{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Script: di_composite_3D.py\n",
    "Author: Hrag Najarian\n",
    "Date: July 25, 2025\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from flox.xarray import xarray_reduce\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from wrf import default_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: To grab the indicies that correspond to the times, latitudes, and longitudes of the WRF dataset file.\n",
    "\n",
    "# Input:\n",
    "\t# file == path to the .nc file\n",
    "\t# times == np.datetime64 array [Start,End]\n",
    "\t# lats == np.array [south,north]\n",
    "\t# lons == np.array [west,east]\n",
    "\n",
    "# Output:\n",
    "\t# time_ind, lat_ind, lon_ind == corresponds to the indicies of the times, lats, and lons provided within that file\n",
    "\n",
    "# Example:\n",
    "\t# file = '/ourdisk/hpc/radclouds/auto_archive_notyet/tape_2copies/hragnajarian/wrfout.files/10day-2015-11-22-12--12-03-00/raw/d01'\n",
    "\t# times = [np.datetime64('2015-11-22T12'), np.datetime64('2015-11-23T12')]\n",
    "\t# lats = [-7.5, 7.5]\n",
    "\t# lons = [90, 110]\n",
    "\t# isel_ind(file, times, lats, lons)\n",
    "\n",
    "def isel_ind(file,times,lats,lons):\n",
    "\t# Declare the variables\n",
    "\ttime_ind = np.zeros(2, dtype=int)\n",
    "\tlat_ind = np.zeros(2, dtype=int)\n",
    "\tlon_ind = np.zeros(2, dtype=int)\n",
    "\t# Open the file\n",
    "\tds = xr.open_dataset(file)\n",
    "\t# Times\n",
    "\ttime_vals = ds.XTIME.compute().values\n",
    "\ttime_mask = (time_vals >= times[0]) & (time_vals <= times[1])\n",
    "\ttime_indices = np.where(time_mask)[0]\n",
    "\ttime_ind = [time_indices[0], time_indices[-1] + 1]  # +1 for Python slicing to include last index\n",
    "\t# Latitudes\n",
    "\tlat_vals = ds.XLAT[0,:,0].compute().values\n",
    "\tlat_mask = (lat_vals >= lats[0]) & (lat_vals <= lats[1])\n",
    "\tlat_indices = np.where(lat_mask)[0]\n",
    "\tlat_ind = [lat_indices[0], lat_indices[-1] + 1]  # +1 for Python slicing to include last index\n",
    "\t# Longitude\n",
    "\tlon_vals = ds.XLONG[0,0,:].compute().values\n",
    "\tlon_mask = (lon_vals >= lons[0]) & (lon_vals <= lons[1])\n",
    "\tlon_indices = np.where(lon_mask)[0]\n",
    "\tlon_ind = [lon_indices[0], lon_indices[-1] + 1]  # +1 for Python slicing to include last index\n",
    "\n",
    "\n",
    "\treturn time_ind, lat_ind, lon_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Opens a dataset with restrictive bounds to make opening large files less intensive\n",
    "\n",
    "# Input:\n",
    "\t# file == path to the .nc file\n",
    "\t# time_ind == indicies (inclusive) of the dates you want to look at\n",
    "\t# lat_ind == indicies (inclusive) of the latitudes you want to look at\n",
    "\t# lon_ind == indicies (inclusive) of the longitudes you want to look at\n",
    "\n",
    "# Output:\n",
    "\t# ds == dataset that corresponds to the times, lats, and lons provided.\n",
    "\n",
    "# Example:\n",
    "\t# To get the indicies, I suggest using the function isel_ind() I have coded up in tandem with this function (see above).\n",
    "\t# file = '/ourdisk/hpc/radclouds/auto_archive_notyet/tape_2copies/hragnajarian/wrfout.files/10day-2015-11-22-12--12-03-00/raw/d01'\n",
    "\t# times = [np.datetime64('2015-11-22T12'), np.datetime64('2015-11-23T12')]\n",
    "\t# lats = [-7.5, 7.5]\n",
    "\t# lons = [90, 110]\n",
    "\t# time_ind, lat_ind, lon_ind = isel_ind(file, times, lats, lons)\n",
    "\t# ds = open_ds(file,time_ind,lat_ind,lon_ind)\n",
    "\n",
    "def open_ds(file, time_ind, lat_ind, lon_ind):\n",
    "\n",
    "\tif time_ind[-1] == -1:\n",
    "\t\tds = xr.open_dataset(file, chunks='auto').isel(\n",
    "\t\tTime=slice(None),\n",
    "\t\t# south_north=slice(lat_ind[0],lat_ind[1]),\n",
    "\t\t# west_east=slice(lon_ind[0],lon_ind[1])\n",
    "\t\tsouth_north=slice(None),\n",
    "\t\twest_east=slice(None)\n",
    "\t)\n",
    "\telse:\n",
    "\t\tds = xr.open_dataset(file, chunks='auto').isel(\n",
    "\t\t\tTime=slice(time_ind[0],time_ind[1]),\n",
    "\t\t\tsouth_north=slice(lat_ind[0],lat_ind[1]),\n",
    "\t\t\twest_east=slice(lon_ind[0],lon_ind[1])\n",
    "\t\t)\n",
    "\t\n",
    "\treturn ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_path(parent_dir: str, sub_dir: str, name: str) -> str:\n",
    "    return f\"{parent_dir}/{sub_dir}/{name}\"\n",
    "\n",
    "def load_variable(file_dict: dict, coords: dict) -> xr.DataArray:\n",
    "    step_start = time.perf_counter()\n",
    "    \n",
    "    ds = open_ds(file_dict['path'], time_ind, lat_ind, lon_ind)\n",
    "        \n",
    "    da = ds[file_dict['varname']].compute()\n",
    "    da = da.assign_coords(coords)\n",
    "    # Replace fill value with nan\n",
    "    da = da.where(da != default_fill(np.float32))\n",
    "    print(f\"{file_dict['description']} loaded ✓\", time.perf_counter() - step_start, \"seconds\")\n",
    "    return da\n",
    "\n",
    "# Function that can removes the bottom_top dimension for 2-D datasets\n",
    "def without_keys(d, keys):\n",
    "\treturn {x: d[x] for x in d if x not in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Create a LocalTime coordinate within your DataArray.\n",
    "\n",
    "def assign_LT_coord(da, dim_num):\n",
    "\thour_offset = (da.XLONG.values[:,0,:]/15).round(decimals=0)\n",
    "\n",
    "\t# Local Time is a function of only Time and Longitude\n",
    "\tif dim_num==2:\n",
    "\t\tlocal_time = np.empty([len(da.Time),len(da.west_east)], dtype=object)\n",
    "\t\tfor i in range(local_time.shape[0]):\n",
    "\t\t\tfor j in range(local_time.shape[1]):\n",
    "\t\t\t\tlocal_time[i,j] = da.Time.values[i] + np.timedelta64(int(hour_offset[0,j]),'h')\n",
    "\t\tda = da.assign_coords(LocalTime=(('Time','west_east'),local_time))\n",
    "\t\n",
    "\t# Local Time is a function of Time, Longitude, and Latitude\n",
    "\telse:\n",
    "\t\tlocal_time = np.empty([len(da.Time),len(da.south_north),len(da.west_east)], dtype='datetime64[ns]')\n",
    "\t\tfor i in range(local_time.shape[0]):\n",
    "\t\t\tfor j in range(local_time.shape[2]):\n",
    "\t\t\t\tlocal_time[i,:,j] = da.Time.values[i] + np.timedelta64(int(hour_offset[0,j]),'h')\n",
    "\t\tda = da.assign_coords(LocalTime=(('Time','south_north','west_east'),local_time))\n",
    "\treturn da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Diurnal Composite\n",
    "\n",
    "def di_process_da(da, varname, lat_bound, lon_bound):\n",
    "\n",
    "\t## Slice in time\n",
    "\tda = da.sel(Time=slice(*time_bound))\n",
    "\n",
    "\t## Rolling mean\n",
    "\tif rolls > 1:\n",
    "\t\tda = da.rolling({'south_north': rolls, 'west_east': rolls}, min_periods=1, center=True).mean()\n",
    "\n",
    "\t## Add local time coordinate and group by hour\n",
    "\tda = assign_LT_coord(da, dim_num=3)\n",
    "\t\n",
    "\t## Group by local time and the 'dim' parameter ensures \n",
    "\t\t# only the Time dimension is averaged into the 'hour' dimension\n",
    "\tda = xarray_reduce(\n",
    "\t\tda, 'LocalTime.hour', func='nanmean', dim='Time',\n",
    "\t\texpected_groups=np.arange(24), isbin=[False], fill_value=np.nan\n",
    "\t).transpose('hour', 'south_north', 'west_east')\n",
    "\n",
    "\t# print(f'dims of da: {da.dims}')\n",
    "\t# print(f'shape of da: {da.shape}')\n",
    "\n",
    "\treturn da.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that can removes the bottom_top dimension for 2-D datasets\n",
    "def without_keys(d, keys):\n",
    "\treturn {x: d[x] for x in d if x not in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded ✓ 0.558335425099358 seconds\n",
      "Created coordinate dictionaries ✓ 4.265348461922258 seconds\n",
      "Open Data Set ✓ 4.285629014018923 seconds\n",
      "Diurnal composite of level 1000 hPa ✓ 1226.8302643198986 seconds\n",
      "Appended diurnal composite into array ✓ 0.009863625979050994 seconds\n",
      "Diurnal composite of level 990 hPa ✓ 34.74659730610438 seconds\n",
      "Appended diurnal composite into array ✓ 0.009961313102394342 seconds\n",
      "Diurnal composite of level 980 hPa ✓ 34.868840030161664 seconds\n",
      "Appended diurnal composite into array ✓ 0.009548943024128675 seconds\n",
      "Diurnal composite of level 970 hPa ✓ 34.4371876521036 seconds\n",
      "Appended diurnal composite into array ✓ 0.009635720867663622 seconds\n",
      "Diurnal composite of level 960 hPa ✓ 34.53212538105436 seconds\n",
      "Appended diurnal composite into array ✓ 0.009853772120550275 seconds\n",
      "Diurnal composite of level 950 hPa ✓ 34.372956863138825 seconds\n",
      "Appended diurnal composite into array ✓ 0.00993927288800478 seconds\n",
      "Diurnal composite of level 920 hPa ✓ 34.695025647990406 seconds\n",
      "Appended diurnal composite into array ✓ 0.009449252858757973 seconds\n",
      "Diurnal composite of level 890 hPa ✓ 667.7327259338927 seconds\n",
      "Appended diurnal composite into array ✓ 0.009848352987319231 seconds\n",
      "Diurnal composite of level 860 hPa ✓ 34.501725422916934 seconds\n",
      "Appended diurnal composite into array ✓ 0.009743812959641218 seconds\n",
      "Diurnal composite of level 830 hPa ✓ 34.80902634304948 seconds\n",
      "Appended diurnal composite into array ✓ 0.0098887849599123 seconds\n",
      "Diurnal composite of level 800 hPa ✓ 34.73345390288159 seconds\n",
      "Appended diurnal composite into array ✓ 0.009908697102218866 seconds\n",
      "Diurnal composite of level 770 hPa ✓ 34.64401807799004 seconds\n",
      "Appended diurnal composite into array ✓ 0.009326571831479669 seconds\n",
      "Diurnal composite of level 740 hPa ✓ 34.64711207104847 seconds\n",
      "Appended diurnal composite into array ✓ 0.00963403913192451 seconds\n",
      "Diurnal composite of level 710 hPa ✓ 34.795413873158395 seconds\n",
      "Appended diurnal composite into array ✓ 0.009472327074036002 seconds\n",
      "Diurnal composite of level 680 hPa ✓ 1642.0858412501402 seconds\n",
      "Appended diurnal composite into array ✓ 0.009520204970613122 seconds\n",
      "Diurnal composite of level 650 hPa ✓ 34.57907894579694 seconds\n",
      "Appended diurnal composite into array ✓ 0.00940773612819612 seconds\n",
      "Diurnal composite of level 620 hPa ✓ 34.57532348507084 seconds\n",
      "Appended diurnal composite into array ✓ 0.009702106937766075 seconds\n",
      "Diurnal composite of level 590 hPa ✓ 34.581501740030944 seconds\n",
      "Appended diurnal composite into array ✓ 0.00965727586299181 seconds\n",
      "Diurnal composite of level 560 hPa ✓ 34.59462016704492 seconds\n",
      "Appended diurnal composite into array ✓ 0.009638577932491899 seconds\n",
      "Diurnal composite of level 530 hPa ✓ 34.47799018397927 seconds\n",
      "Appended diurnal composite into array ✓ 0.009672245010733604 seconds\n",
      "Diurnal composite of level 500 hPa ✓ 34.9336379179731 seconds\n",
      "Appended diurnal composite into array ✓ 0.009433969156816602 seconds\n",
      "Diurnal composite of level 470 hPa ✓ 4228.818348693894 seconds\n",
      "Appended diurnal composite into array ✓ 0.009515596088021994 seconds\n",
      "Diurnal composite of level 440 hPa ✓ 34.7760527220089 seconds\n",
      "Appended diurnal composite into array ✓ 0.009505800902843475 seconds\n",
      "Diurnal composite of level 410 hPa ✓ 34.52196664712392 seconds\n",
      "Appended diurnal composite into array ✓ 0.009795494144782424 seconds\n",
      "Diurnal composite of level 380 hPa ✓ 34.78312619193457 seconds\n",
      "Appended diurnal composite into array ✓ 0.009655904024839401 seconds\n",
      "Diurnal composite of level 350 hPa ✓ 34.958765369839966 seconds\n",
      "Appended diurnal composite into array ✓ 0.009755128994584084 seconds\n",
      "Diurnal composite of level 300 hPa ✓ 34.992655711015686 seconds\n",
      "Appended diurnal composite into array ✓ 0.009879286866635084 seconds\n",
      "Diurnal composite of level 250 hPa ✓ 34.82720359088853 seconds\n",
      "Appended diurnal composite into array ✓ 0.009677349124103785 seconds\n",
      "Diurnal composite of level 200 hPa ✓ 371.0308497219812 seconds\n",
      "Appended diurnal composite into array ✓ 0.011865586042404175 seconds\n",
      "Diurnal composite of level 150 hPa ✓ 32.945675218012184 seconds\n",
      "Appended diurnal composite into array ✓ 0.01182776503264904 seconds\n",
      "Diurnal composite of level 100 hPa ✓ 32.69628575304523 seconds\n",
      "Appended diurnal composite into array ✓ 0.011604417115449905 seconds\n",
      "Diurnal composite of level 50 hPa ✓ 32.91528131603263 seconds\n",
      "Appended diurnal composite into array ✓ 0.009681445080786943 seconds\n",
      "W saved ✓ 0.8062584369909018 seconds\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "#######################################################################################\n",
    "\n",
    "## What 3-D variables would you like to diurnally coposite?\n",
    "L2_vars = ['W']\n",
    "## Slice lat and lon bounds set for diurnal calculations\n",
    "lat_bound = [-10, 5]\n",
    "lon_bound = [80, 135]\n",
    "interp_P_levels = np.concatenate((np.arange(1000,950,-10),np.arange(950,350,-30),np.arange(350,0,-50)))  # Should be in hPa\n",
    "rolls = 1   # Smoother\n",
    "\n",
    "## Assign parent_dir that is where your raw, L1, L2, etc. directories live.\n",
    "# parent_dir = sys.argv[1]\n",
    "parent_dir = '/ourdisk/hpc/radclouds/auto_archive_notyet/tape_2copies/hragnajarian/wrfout.files/10day-2015-11-22-12--12-03-00'\n",
    "time_bound = [np.datetime64('2015-11-23T01'), np.datetime64('2015-12-02T00')] if '2015-11-22-12' in parent_dir else [np.datetime64('2015-12-10T01'), np.datetime64('2015-12-20T00')]\n",
    "\n",
    "#######################################################################################\n",
    "#######################################################################################\n",
    "\n",
    "start1_time = time.perf_counter()\n",
    "\n",
    "## Assign bottom_top coordinates to make computations simpler using xarray\n",
    "time_ind, lat_ind, lon_ind = isel_ind(build_path(parent_dir, \"raw\", \"d02\"), time_bound, lat_bound, lon_bound)\n",
    "ds_raw = open_ds(build_path(parent_dir, \"raw\", \"d02\"),time_ind, lat_ind, lon_ind)\n",
    "step1_time = time.perf_counter()\n",
    "print('Dataset loaded \\N{check mark}', step1_time-start1_time, 'seconds')\n",
    "\n",
    "\n",
    "## Coordinate dictionaries\n",
    "step1_time = time.perf_counter()\n",
    "\n",
    "coords = dict(\n",
    "\tXLAT=(('Time','south_north','west_east'),ds_raw.XLAT.values),\n",
    "\tXLONG=(('Time','south_north','west_east'),ds_raw.XLONG.values),\n",
    "\tbottom_top=(('bottom_top'),interp_P_levels),\n",
    "\tTime=('Time',ds_raw.XTIME.values),\n",
    "\tsouth_north=(('south_north'),ds_raw.XLAT[0,:,0].values),\n",
    "\twest_east=(('west_east'),ds_raw.XLONG[0,0,:].values)\n",
    "\t)\n",
    "di_coords = dict(\n",
    "\thour=('hour',np.arange(0,24)),\n",
    "\tbottom_top=(('bottom_top'),interp_P_levels),\n",
    "\tsouth_north=(('south_north'),ds_raw.XLAT[0,:,0].values),\n",
    "\twest_east=(('west_east'),ds_raw.XLONG[0,0,:].values)\n",
    "\t)\n",
    "\n",
    "step2_time = time.perf_counter()\n",
    "print('Created coordinate dictionaries \\N{check mark}', step2_time-step1_time, 'seconds')\n",
    "\n",
    "\n",
    "## Create full paths of the variables to vertically integrate\n",
    "L2_dir = parent_dir + '/L2'\n",
    "prefix = 'd02_sunrise_interp_' if 'CRFoff' in parent_dir else 'd02_interp_'\n",
    "L2_var_files = {f\"{prefix}{var}\" for var in L2_vars}\n",
    "L2_paths = [os.path.join(L2_dir, f) for f in os.listdir(L2_dir) if f in L2_var_files]\n",
    "\n",
    "\n",
    "## Loop through the variable paths\n",
    "for i, path in enumerate(L2_paths):\n",
    "\n",
    "\tstart2_time = time.perf_counter()\n",
    "\n",
    "\t## Open data set, index appropriate variable, assign coords, and replace fill values with nans\n",
    "\tds = open_ds(path, time_ind, lat_ind, lon_ind)\n",
    "\tda = ds[L2_vars[i]].assign_coords(coords)\n",
    "\t# da = da[:,0:2]\t\t# Remove once you are done debugging\n",
    "\t\t# Important step over regions of terrain\n",
    "\tda = da.where(da != default_fill(np.float32))\n",
    "\tstep2_time = time.perf_counter()\n",
    "\tprint('Open Data Set \\N{check mark}', step2_time-step1_time, 'seconds')\n",
    "\n",
    "\t## Create the 4-D array that will be populated diurnally\n",
    "\tda_di = np.full((24, len(interp_P_levels), *da.shape[2:]), np.nan, dtype=np.float32)\n",
    "\t\n",
    "\t\n",
    "\t## Loop over all the pressure layers \n",
    "\tfor j, level in enumerate(interp_P_levels):\n",
    "\n",
    "\t\tstep1_time = time.perf_counter()\n",
    "\t\t## Diurnally Composite\n",
    "\t\tda_di_z = di_process_da(da[:,j], L2_vars[i], lat_bound, lon_bound)\n",
    "\t\tstep2_time = time.perf_counter()\n",
    "\t\tprint(f'Diurnal composite of level {level} hPa \\N{check mark}', step2_time-step1_time, 'seconds')\n",
    "\n",
    "\t\tstep1_time = time.perf_counter()\n",
    "\t\t## Append Diurnal composite into array\n",
    "\t\tda_di[:,j] = da_di_z\n",
    "\t\tstep2_time = time.perf_counter()\n",
    "\t\tprint(f'Appended diurnal composite into array \\N{check mark}', step2_time-step1_time, 'seconds')\n",
    "\n",
    "\n",
    "\t## Assign coordinates before saving as an .nc file\n",
    "\tda_di = xr.DataArray(da_di, name='W', coords=di_coords, dims=('hour', 'bottom_top', 'south_north', 'west_east'))\n",
    "\n",
    "\t## Assign attributes\n",
    "\tda_di = da_di.assign_attrs(\n",
    "\t\tUnits=da.attrs['units'],\n",
    "\t\trolling=str(rolls),\n",
    "\t\tsim='NCRF' if 'CRFoff' in path else 'CTRL',\n",
    "\t\tLongitude_Bounds=f'{lon_bound[0]} to {lon_bound[1]}',\n",
    "\t\tLatitude_Bounds=f'{lat_bound[0]} to {lat_bound[1]}',\n",
    "\t\tTime_Bounds=f'{time_bound[0]} to {time_bound[1]}')\n",
    "\n",
    "\t## Save File\n",
    "\tstep1_time = time.perf_counter()\n",
    "\tout_path = f'{parent_dir}/L4/{L2_vars[i]}_di_sunrise' if 'CRFoff' in parent_dir else f'{parent_dir}/L4/{L2_vars[i]}_di_ctrl'\n",
    "\tda_di.to_netcdf(path=out_path, mode='w', format='NETCDF4', compute=True) #  ,unlimited_dims='Time'\n",
    "\tstep2_time = time.perf_counter()\n",
    "\tprint(f'{L2_vars[i]} saved \\N{check mark}', step2_time-step1_time, 'seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign coordinates before saving as an .nc file\n",
    "da_di = xr.DataArray(da_di, name='W', coords=di_coords, dims=('hour', 'bottom_top', 'south_north', 'west_east'))\n",
    "\n",
    "## Assign attributes\n",
    "da_di = da_di.assign_attrs(\n",
    "\tUnits=da.attrs['units'],\n",
    "\trolling=str(rolls),\n",
    "\tsim='NCRF' if 'CRFoff' in path else 'CTRL',\n",
    "\tLongitude_Bounds=f'{lon_bound[0]} to {lon_bound[1]}',\n",
    "\tLatitude_Bounds=f'{lat_bound[0]} to {lat_bound[1]}',\n",
    "\tTime_Bounds=f'{time_bound[0]} to {time_bound[1]}')\n",
    "\n",
    "## Save File\n",
    "# step1_time = time.perf_counter()\n",
    "out_path = f'{parent_dir}/L4/{L2_vars[i]}_di_sunrise' if 'CRFoff' in parent_dir else f'{parent_dir}/L4/{L2_vars[i]}_di_ctrl'\n",
    "da_di.to_netcdf(path=out_path, mode='w', format='NETCDF4', compute=True) #  ,unlimited_dims='Time'\n",
    "# step2_time = time.perf_counter()\n",
    "# print(f'{L2_vars[i]} saved \\N{check mark}', step2_time-step1_time, 'seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WRF_Xarray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
